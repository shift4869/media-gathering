# coding: utf-8
"""ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼

Fav/Retweetã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã®ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ {CONFIG_FILE_NAME} ã«ã‚ã‚‹config.iniãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹
"""

import configparser
import json
import logging.config
import os
import shutil
import time
import urllib
from abc import ABCMeta, abstractmethod
from datetime import datetime
from logging import INFO, getLogger
from pathlib import Path

import requests
import slackweb
from plyer import notification

from PictureGathering import WriteHTML, Archiver, GoogleDrive
from PictureGathering.LinkSearch.LinkSearcher import LinkSearcher
from PictureGathering.LogMessage import MSG
from PictureGathering.Model import ExternalLink
from PictureGathering.v2.TweetInfo import TweetInfo
from PictureGathering.v2.TwitterAPI import TwitterAPI
from PictureGathering.v2.TwitterAPIEndpoint import TwitterAPIEndpoint, TwitterAPIEndpointName

logging.config.fileConfig("./log/logging.ini", disable_existing_loggers=False)
for name in logging.root.manager.loggerDict:
    # è‡ªåˆ†ä»¥å¤–ã®ã™ã¹ã¦ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ­ã‚°å‡ºåŠ›ã‚’æŠ‘åˆ¶
    if "PictureGathering" not in name:
        getLogger(name).disabled = True
logger = getLogger(__name__)
logger.setLevel(INFO)


class Crawler(metaclass=ABCMeta):
    """ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼

    Fav/Retweetã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã®ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹

    Note:
        ã“ã®ã‚¯ãƒ©ã‚¹ã‚’ç¶™æ‰¿ã™ã‚‹ãŸã‚ã«ã¯@abstractmethodãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã¤ãã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Ÿè£…ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚

    Args:
        metaclass (metaclass): æŠ½è±¡ã‚¯ãƒ©ã‚¹æŒ‡å®š

    Attributes:
        CONFIG_FILE_NAME (str): è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        config (ConfigParser): è¨­å®šiniæ§‹é€ ä½“
        TW_V2_API_KEY (str): TwitterAPI_v2åˆ©ç”¨APIã‚­ãƒ¼
        TW_V2_API_KEY_SECRET (str): TwitterAPI_v2åˆ©ç”¨APIã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚­ãƒ¼
        TW_V2_ACCESS_TOKEN (str): TwitterAPI_v2ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚­ãƒ¼
        TW_V2_ACCESS_TOKEN_SECRET (str): TwitterAPI_v2ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚­ãƒ¼
        DISCORD_WEBHOOK_URL (str): Discordã®Webhook URL
        LN_TOKEN_KEY (str): LINE notifyã®ãƒˆãƒ¼ã‚¯ãƒ³
        SLACK_WEBHOOK_URL (str): Slackã®Webhook URL
        twitter (TwitterAPI): TwitterAPIåˆ©ç”¨ã‚¯ãƒ©ã‚¹
        lsb (LinkSearcher): å¤–éƒ¨ãƒªãƒ³ã‚¯æ¢ç´¢æ©Ÿæ§‹ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹
        db_cont (DBControllerBase): DBæ“ä½œç”¨ã‚¯ãƒ©ã‚¹ï¼ˆå®Ÿä½“ã¯Crawleræ´¾ç”Ÿã‚¯ãƒ©ã‚¹ã§è¦å®šï¼‰
        save_path (str): ãƒ¡ãƒ‡ã‚£ã‚¢ä¿å­˜å…ˆãƒ‘ã‚¹
        type (str): ç¶™æ‰¿å…ˆã‚’è¡¨ã™ã‚¿ã‚¤ãƒ—è­˜åˆ¥{Fav, RT}
        add_cnt (int): æ–°è¦è¿½åŠ ã—ãŸãƒ¡ãƒ‡ã‚£ã‚¢ã®æ•°
        del_cnt (int): å‰Šé™¤ã—ãŸãƒ¡ãƒ‡ã‚£ã‚¢ã®æ•°
        add_url_list (list): æ–°è¦è¿½åŠ ã—ãŸãƒ¡ãƒ‡ã‚£ã‚¢ã®URLãƒªã‚¹ãƒˆ
        del_url_list (list): å‰Šé™¤ã—ãŸãƒ¡ãƒ‡ã‚£ã‚¢ã®URLãƒªã‚¹ãƒˆ
    """
    CONFIG_FILE_NAME = "./config/config.ini"

    def __init__(self):
        logger.info(MSG.CRAWLER_INIT_START.value)

        def notify(error_message: str):
            notification.notify(
                title="Picture Gathering å®Ÿè¡Œã‚¨ãƒ©ãƒ¼",
                message=error_message,
                app_name="Picture Gathering",
                timeout=10
            )

        self.config = configparser.ConfigParser()
        try:
            if not self.config.read(self.CONFIG_FILE_NAME, encoding="utf8"):
                raise IOError

            config = self.config["save_directory"]
            Path(config["save_fav_path"]).mkdir(parents=True, exist_ok=True)
            Path(config["save_retweet_path"]).mkdir(parents=True, exist_ok=True)

            config = self.config["twitter_token_keys_v2"]
            self.TW_V2_API_KEY = config["api_key"]
            self.TW_V2_API_KEY_SECRET = config["api_key_secret"]
            self.TW_V2_ACCESS_TOKEN = config["access_token"]
            self.TW_V2_ACCESS_TOKEN_SECRET = config["access_token_secret"]
            self.twitter = TwitterAPI(
                self.TW_V2_API_KEY,
                self.TW_V2_API_KEY_SECRET,
                self.TW_V2_ACCESS_TOKEN,
                self.TW_V2_ACCESS_TOKEN_SECRET
            )

            config = self.config["discord_webhook_url"]
            self.DISCORD_WEBHOOK_URL = config["webhook_url"]

            config = self.config["line_token_keys"]
            self.LN_TOKEN_KEY = config["token_key"]

            config = self.config["slack_webhook_url"]
            self.SLACK_WEBHOOK_URL = config["webhook_url"]

            # å¤–éƒ¨ãƒªãƒ³ã‚¯æ¢ç´¢æ©Ÿæ§‹ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            self.link_search_register()
        except IOError:
            error_message = self.CONFIG_FILE_NAME + " is not exist or cannot be opened."
            logger.exception(error_message)
            notify(error_message)
            exit(-1)
        except KeyError:
            error_message = "invalid config file error."
            logger.exception(error_message)
            notify(error_message)
            exit(-1)
        except ValueError as e:
            error_message = "Twitter API setup error."
            logger.exception(e)
            notify(error_message)
            exit(-1)
        except Exception:
            error_message = "unknown error."
            logger.exception(error_message)
            notify(error_message)
            exit(-1)

        # æ´¾ç”Ÿã‚¯ãƒ©ã‚¹ã§å®Ÿä½“ãŒä»£å…¥ã•ã‚Œã‚‹ãƒ¡ãƒ³ãƒ
        # æƒ…å ±ä¿æŒDBã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼
        self.db_cont = None
        # ä¿å­˜å…ˆãƒ‘ã‚¹
        self.save_path = Path()
        # ã‚¯ãƒ­ãƒ¼ãƒ©ã‚¿ã‚¤ãƒ— = ["Fav", "RT"]
        self.type = ""

        # å‡¦ç†ä¸­ï½å‡¦ç†å®Œäº†å¾Œã«ä½¿ç”¨ã™ã‚‹è¿½åŠ å‰Šé™¤ã‚«ã‚¦ãƒ³ãƒˆãƒ»ãƒªã‚¹ãƒˆ
        self.add_cnt = 0
        self.del_cnt = 0
        self.add_url_list = []
        self.del_url_list = []
        logger.info(MSG.CRAWLER_INIT_DONE.value)

    def link_search_register(self) -> int:
        """å¤–éƒ¨ãƒªãƒ³ã‚¯æ¢ç´¢æ©Ÿæ§‹ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

        Notes:
            self.lsbã«è¨­å®šã™ã‚‹

        Returns:
            int: æˆåŠŸæ™‚0
        """
        # å¤–éƒ¨ãƒªãƒ³ã‚¯æ¢ç´¢ã‚’ç™»éŒ²
        self.lsb = LinkSearcher.create(self.config)
        return 0

    def get_exist_filelist(self) -> list:
        """self.save_pathã«å­˜åœ¨ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åä¸€è¦§ã‚’å–å¾—ã™ã‚‹

        Returns:
            list: self.save_pathã«å­˜åœ¨ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åä¸€è¦§
        """
        filelist = []
        save_path = Path(self.save_path)

        # save_pathé…ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã‚’æœæŸ»ã—ã€å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†ã™ã‚‹
        # (æ›´æ–°æ—¥æ™‚ï¼ˆmtimeï¼‰, ãƒ‘ã‚¹æ–‡å­—åˆ—)ã®ã‚¿ãƒ—ãƒ«ã‚’ãƒªã‚¹ãƒˆã«ä¿æŒã™ã‚‹
        filelist_tp = [(sp.stat().st_mtime, str(sp)) for sp in save_path.glob("**/*") if sp.is_file()]

        # æ›´æ–°æ—¥æ™‚ï¼ˆmtimeï¼‰ã§ã‚½ãƒ¼ãƒˆã—ã€æœ€æ–°ã®ã‚‚ã®ã‹ã‚‰filelistã«è¿½åŠ ã™ã‚‹
        for mtime, path in sorted(filelist_tp, reverse=True):
            filelist.append(path)

        return filelist

    def shrink_folder(self, holding_file_num: int) -> int:
        """ãƒ•ã‚©ãƒ«ãƒ€å†…ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•°ã‚’ä¸€å®šã«ã™ã‚‹

        Args:
            holding_file_num (int): ãƒ•ã‚©ãƒ«ãƒ€å†…ã«æ®‹ã™ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•°

        Returns:
            int: 0(æˆåŠŸ)
        """
        filelist = self.get_exist_filelist()

        # ãƒ•ã‚©ãƒ«ãƒ€ã«æ—¢ã«ä¿å­˜ã—ã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯URLã®æƒ…å ±ãŒãªã„
        # ãƒ•ã‚¡ã‚¤ãƒ«åã¨ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’çµã³ã¤ã‘ã¦URLã‚’æ‰‹å‹•ã§ç”Ÿæˆã™ã‚‹
        # twitterã®ç”»åƒURLã®ä»•æ§˜ãŒå¤‰ã‚ã£ãŸã‚‰ã“ã“ã‚‚å¤‰ãˆã‚‹å¿…è¦ãŒã‚ã‚‹
        # http://pbs.twimg.com/media/{file.basename}.jpg:orig
        # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®URLã¯DBã«å•ã„åˆã‚ã›ã‚‹
        add_img_filename = []
        for i, file in enumerate(filelist):
            url = ""
            file_path = Path(file)

            if ".mp4" == file_path.suffix:  # media_type == "video":
                url = self.get_media_url(file_path.name)
            else:  # media_type == "photo":
                image_base_url = "http://pbs.twimg.com/media/{}:orig"
                url = image_base_url.format(file_path.name)

            if i > holding_file_num:
                file_path.unlink(missing_ok=True)
                self.del_cnt += 1
                self.del_url_list.append(url)
            else:
                # self.add_url_list.append(url)
                add_img_filename.append(file_path.name)

        # å­˜åœ¨ãƒãƒ¼ã‚­ãƒ³ã‚°ã‚’æ›´æ–°ã™ã‚‹
        self.update_db_exist_mark(add_img_filename)

        return 0

    def update_db_exist_mark(self, add_img_filename):
        # å­˜åœ¨ãƒãƒ¼ã‚­ãƒ³ã‚°ã‚’æ›´æ–°ã™ã‚‹
        self.db_cont.clear_flag()
        self.db_cont.update_flag(add_img_filename, 1)

    def get_media_url(self, filename):
        # 'https://video.twimg.com/ext_tw_video/1139678486296031232/pu/vid/640x720/b0ZDq8zG_HppFWb6.mp4?tag=10'
        response = self.db_cont.select_from_media_url(filename)
        url = response[0]["url"] if len(response) == 1 else ""
        return url

    @abstractmethod
    def make_done_message(self) -> str:
        """å®Ÿè¡Œå¾Œã®çµæœæ–‡å­—åˆ—ã‚’ç”Ÿæˆã™ã‚‹
        """
        pass

    def end_of_process(self) -> int:
        """å®Ÿè¡Œå¾Œã®å¾Œå‡¦ç†

        Returns:
            int: æˆåŠŸæ™‚0
        """
        logger.info("")

        done_msg = self.make_done_message()

        logger.info("\t".join(done_msg.splitlines()))

        config = self.config["notification"]

        WriteHTML.WriteResultHTML(self.type, self.db_cont)
        if self.add_cnt != 0 or self.del_cnt != 0:
            if self.add_cnt != 0:
                logger.info("add url:")
                for url in self.add_url_list:
                    logger.info(url)

            if self.del_cnt != 0:
                logger.info("del url:")
                for url in self.del_url_list:
                    logger.info(url)

            if self.type == "Fav" and config.getboolean("is_post_fav_done_reply"):
                self.post_tweet(done_msg)
                logger.info("Reply posted.")

            if self.type == "RT" and config.getboolean("is_post_retweet_done_reply"):
                self.post_tweet(done_msg)
                logger.info("Reply posted.")

            if config.getboolean("is_post_discord_notify"):
                self.post_discord_notify(done_msg)
                logger.info("Discord Notify posted.")

            if config.getboolean("is_post_line_notify"):
                self.post_line_notify(done_msg)
                logger.info("Line Notify posted.")

            if config.getboolean("is_post_slack_notify"):
                self.post_slack_notify(done_msg)
                logger.info("Slack Notify posted.")

            # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã™ã‚‹è¨­å®šã®å ´åˆ
            config = self.config["archive"]
            if config.getboolean("is_archive"):
                zipfile_path = Archiver.MakeZipFile(config.get("archive_temp_path"), self.type)
                logger.info("Archive File Created.")
                if config.getboolean("is_send_google_drive") and zipfile_path != "":
                    GoogleDrive.UploadToGoogleDrive(zipfile_path, config.get("google_service_account_credentials"))
                    logger.info("Google Drive Send.")

        # å¤ã„é€šçŸ¥ãƒªãƒ—ãƒ©ã‚¤ã‚’æ¶ˆã™
        config = self.config["notification"]
        if config.getboolean("is_post_fav_done_reply") or config.getboolean("is_post_retweet_done_reply"):
            targets = self.db_cont.update_del()
            for target in targets:
                url = TwitterAPIEndpoint.make_url(TwitterAPIEndpointName.DELETE_TWEET, target["tweet_id"])
                response = self.twitter.delete(url)  # tweet_id

        logger.info("End Of " + self.type + " Crawl Process.")
        return 0

    def post_tweet(self, tweet_str: str) -> int:
        """å®Ÿè¡Œå®Œäº†ãƒ„ã‚¤ãƒ¼ãƒˆã‚’ãƒã‚¹ãƒˆã™ã‚‹

        Args:
            str (str): ãƒã‚¹ãƒˆã™ã‚‹æ–‡å­—åˆ—

        Returns:
            int: æˆåŠŸæ™‚0ã€å¤±æ•—æ™‚-1
        """
        reply_user_name = self.config["notification"]["reply_to_user_name"]
        url = TwitterAPIEndpoint.make_url(TwitterAPIEndpointName.POST_TWEET)

        tweet_str = "@" + reply_user_name + " " + tweet_str
        params = {
            "text": tweet_str,
        }

        response = self.twitter.post(url, params)
        if not response:
            logger.error("post_tweet failed.")
            return -1

        tweet = response
        self.db_cont.upsert_del(tweet)

        return 0

    def post_discord_notify(self, str: str) -> int:
        """Discordé€šçŸ¥ãƒã‚¹ãƒˆ

        Args:
            str (str): Discordã«é€šçŸ¥ã™ã‚‹æ–‡å­—åˆ—

        Returns:
            int: 0(æˆåŠŸ)
        """
        url = self.DISCORD_WEBHOOK_URL

        headers = {
            "Content-Type": "application/json"
        }

        # "content": "ğŸ˜æ™®é€šã®çµµæ–‡å­—\r:sunglasses:Discordã®çµµæ–‡å­—ã‚‚:ok_woman:"
        payload = {
            "content": str
        }

        response = requests.post(url, headers=headers, data=json.dumps(payload))

        if response.status_code != 204:  # æˆåŠŸã™ã‚‹ã¨204 No ContentãŒè¿”ã£ã¦ãã‚‹
            logger.error("Error code: {0}".format(response.status_code))
            return -1

        return 0

    def post_line_notify(self, str: str) -> int:
        """LINEé€šçŸ¥ãƒã‚¹ãƒˆ

        Args:
            str (str): LINEã«é€šçŸ¥ã™ã‚‹æ–‡å­—åˆ—

        Returns:
            int: 0(æˆåŠŸ)
        """
        url = "https://notify-api.line.me/api/notify"
        token = self.LN_TOKEN_KEY

        headers = {"Authorization": "Bearer " + token}
        payload = {"message": str}

        response = requests.post(url, headers=headers, params=payload)

        if response.status_code != 200:
            logger.error("Error code: {0}".format(response.status_code))
            return -1

        return 0

    def post_slack_notify(self, str: str) -> int:
        """Slacké€šçŸ¥ãƒã‚¹ãƒˆ

        Args:
            str (str): Slackã«é€šçŸ¥ã™ã‚‹æ–‡å­—åˆ—

        Returns:
            int: 0(æˆåŠŸ)
        """
        try:
            slack = slackweb.Slack(url=self.SLACK_WEBHOOK_URL)
            slack.notify(text="<!here> " + str)
        except ValueError:
            logger.error("Webhook URL error: {0} is invalid".format(self.SLACK_WEBHOOK_URL))
            return -1

        return 0

    def tweet_media_saver_v2(self, tweet_info: TweetInfo, atime: float, mtime: float) -> int:
        """æŒ‡å®šURLã®ãƒ¡ãƒ‡ã‚£ã‚¢ã‚’ä¿å­˜ã™ã‚‹

        Args:
            tweet_info (TweetInfo): ãƒ¡ãƒ‡ã‚£ã‚¢å«ã‚€ãƒ„ã‚¤ãƒ¼ãƒˆæƒ…å ±
            atime (float): æŒ‡å®šæ›´æ–°æ—¥æ™‚
            mtime (float): æŒ‡å®šæ›´æ–°æ—¥æ™‚

        Returns:
            int: æˆåŠŸæ™‚0ã€æ—¢ã«å­˜åœ¨ã—ã¦ã„ã‚‹ãƒ¡ãƒ‡ã‚£ã‚¢ã ã£ãŸå ´åˆ1ã€éå»ã«å–å¾—æ¸ˆã®ãƒ¡ãƒ‡ã‚£ã‚¢ã ã£ãŸå ´åˆ2ã€
                 å¤±æ•—æ™‚ï¼ˆãƒ¡ãƒ‡ã‚£ã‚¢è¾æ›¸æ§‹é€ ãŒã‚¨ãƒ©ãƒ¼ã€urlãŒå–å¾—ã§ããªã„ï¼‰-1
        """
        url_orig = tweet_info.media_url
        url_thumbnail = tweet_info.media_thumbnail_url
        file_name = tweet_info.media_filename
        save_file_path = Path(self.save_path) / file_name
        save_file_fullpath = save_file_path.absolute()

        # éå»ã«å–å¾—æ¸ˆã‹ã©ã†ã‹èª¿ã¹ã‚‹
        if self.db_cont.select_from_media_url(file_name) != []:
            logger.debug(save_file_fullpath.name + " -> skip")
            return 2

        if not save_file_fullpath.is_file():
            # URLã‹ã‚‰ãƒ¡ãƒ‡ã‚£ã‚¢ã‚’å–å¾—ã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’è¨­å®šã™ã‚‹ãŸã‚ã«urlopenã‚’åˆ©ç”¨
            # urllib.request.urlretrieve(url_orig, save_file_fullpath)
            try:
                data = urllib.request.urlopen(url_orig, timeout=60).read()
                with save_file_fullpath.open(mode="wb") as f:
                    f.write(data)
            except Exception:
                # URLã‹ã‚‰ã®ãƒ¡ãƒ‡ã‚£ã‚¢å–å¾—ã«å¤±æ•—
                # å‰Šé™¤ã•ã‚Œã¦ã„ãŸå ´åˆãªã©
                logger.info(save_file_fullpath.name + " -> failed.")
                return -1
            self.add_url_list.append(url_orig)

            # DBæ“ä½œ
            # db_cont.upsert_v2æ´¾ç”Ÿã‚¯ãƒ©ã‚¹ã«ã‚ˆã£ã¦å‘¼ã³åˆ†ã‘ã‚‰ã‚Œã‚‹
            dts_format = "%Y-%m-%d %H:%M:%S"
            params = {
                "is_exist_saved_file": True,
                "img_filename": file_name,
                "url": url_orig,
                "url_thumbnail": url_thumbnail,
                "tweet_id": tweet_info.tweet_id,
                "tweet_url": tweet_info.tweet_url,
                "created_at": tweet_info.created_at,
                "user_id": tweet_info.user_id,
                "user_name": tweet_info.user_name,
                "screan_name": tweet_info.screan_name,
                "tweet_text": tweet_info.tweet_text,
                "tweet_via": tweet_info.tweet_via,
                "saved_localpath": str(save_file_fullpath),
                "saved_created_at": datetime.now().strftime(dts_format),
            }
            include_blob = self.config["db"].getboolean("save_blob")
            try:
                if include_blob:
                    with open(save_file_fullpath, "rb") as fout:
                        params["media_blob"] = fout.read()
                        params["media_size"] = len(params["media_blob"])
                else:
                    params["media_blob"] = None
                    params["media_size"] = Path(save_file_fullpath).stat().st_size
            except Exception:
                params["media_blob"] = None
                params["media_size"] = -1
            self.db_cont.upsert(params)

            # æ›´æ–°æ—¥æ™‚ã‚’ä¸Šæ›¸ã
            config = self.config["timestamp"]
            if config.getboolean("timestamp_created_at"):
                os.utime(save_file_fullpath, (atime, mtime))

            # ãƒ­ã‚°æ›¸ãå‡ºã—
            logger.info(save_file_fullpath.name + " -> done")
            self.add_cnt += 1

            # å¸¸ã«ä¿å­˜ã™ã‚‹è¨­å®šã®å ´åˆã¯ã‚³ãƒ”ãƒ¼ã™ã‚‹
            config = self.config["db"]
            if config.getboolean("save_permanent_image_flag"):
                shutil.copy2(save_file_fullpath, config["save_permanent_image_path"])

            # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã™ã‚‹è¨­å®šã®å ´åˆ
            config = self.config["archive"]
            if config.getboolean("is_archive"):
                shutil.copy2(save_file_fullpath, config["archive_temp_path"])
        else:
            # æ—¢ã«å­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆ
            logger.debug(save_file_fullpath.name + " -> exist")
            return 1
        return 0

    def interpret_tweets_v2(self, tweet_info_list: list[TweetInfo]) -> None:
        for tweet_info in tweet_info_list:
            """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã«ã¤ã„ã¦
                https://srbrnote.work/archives/4054
                ä½œæˆæ—¥æ™‚:ctime, æ›´æ–°æ—¥æ™‚:mtime, ã‚¢ã‚¯ã‚»ã‚¹æ—¥æ™‚:atimeãŒã‚ã‚‹
                ctimeã¯OSä¾å­˜ã®ãŸã‚è¨­å®šã«ã¯å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦
                ã“ã“ã§ã¯
                    Favãªã‚‰ã°atime=mtime=ãƒ„ã‚¤ãƒ¼ãƒˆæŠ•ç¨¿æ—¥æ™‚ ã¨ã™ã‚‹
                    RTãªã‚‰ã°atime=mtime=ãƒ„ã‚¤ãƒ¼ãƒˆæŠ•ç¨¿æ—¥æ™‚ ã¨ã™ã‚‹
                    ï¼ˆIS_APPLY_NOW_TIMESTAMP == Trueãªã‚‰ã°åé›†æ™‚ã®æ™‚åˆ» ã¨ã™ã‚‹ï¼Ÿï¼‰
                åé›†ã•ã‚ŒãŸãƒ„ã‚¤ãƒ¼ãƒˆã®æŠ•ç¨¿æ—¥æ™‚ã¯DBã®created_até …ç›®ã«ä¿æŒã•ã‚Œã‚‹
            """
            IS_APPLY_NOW_TIMESTAMP = False
            atime = mtime = -1
            if IS_APPLY_NOW_TIMESTAMP:
                atime = mtime = time.time()
            else:
                dts_format = "%Y-%m-%d %H:%M:%S"
                media_tweet_created_time = tweet_info.created_at
                created_time = time.strptime(media_tweet_created_time, dts_format)
                atime = mtime = time.mktime(
                    (created_time.tm_year,
                     created_time.tm_mon,
                     created_time.tm_mday,
                     created_time.tm_hour,
                     created_time.tm_min,
                     created_time.tm_sec,
                     0, 0, -1)
                )

            # ãƒ¡ãƒ‡ã‚£ã‚¢ä¿å­˜
            self.tweet_media_saver_v2(tweet_info, atime, mtime)

    def trace_external_link(self, external_link_list: list[ExternalLink]) -> None:
        # å¤–éƒ¨ãƒªãƒ³ã‚¯æ¢ç´¢
        for external_link in external_link_list:
            url = external_link.external_link_url
            # éå»ã«å–å¾—æ¸ˆã‹ã©ã†ã‹èª¿ã¹ã‚‹
            if self.db_cont.select_external_link(url) != []:
                logger.debug(url + " : in DB exist -> skip")
                continue
            if self.lsb.can_fetch(url):
                # å¤–éƒ¨ãƒªãƒ³ã‚¯å…ˆã‚’å–å¾—ã—ã¦ä¿å­˜
                self.lsb.fetch(url)
                # DBã«ã‚¢ãƒ‰ãƒ¬ã‚¹æƒ…å ±ã‚’ä¿å­˜
                self.db_cont.upsert_external_link([external_link])

    @abstractmethod
    def crawl(self) -> int:
        """ä¸€é€£ã®å®Ÿè¡Œãƒ¡ã‚½ãƒƒãƒ‰ã‚’ã¾ã¨ã‚ã‚‹

        Returns:
            int: 0(æˆåŠŸ)
        """
        return 0


if __name__ == "__main__":
    import PictureGathering.FavCrawler as FavCrawler
    c = FavCrawler.FavCrawler()
    c.crawl()
